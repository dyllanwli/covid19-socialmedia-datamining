{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ujson\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessTwitter:\n",
    "    def __init__(self):\n",
    "        self.base_path = os.environ[\"SCRATCH\"]\n",
    "\n",
    "        input_folder = \"covid-map/twitter-dataset-covid-all\"\n",
    "        self.input_folder_path = os.path.join(self.base_path, input_folder)\n",
    "\n",
    "        output_folder = \"covid-map/twitter-dataset-processed-1\"\n",
    "        self.output_folder_path = os.path.join(self.base_path, output_folder)\n",
    "\n",
    "        # csv path list splited by month\n",
    "        self.tweets_filepath_set = self._read_dirs(self.input_folder_path)\n",
    "        self.sample_json_file_path = self.tweets_filepath_set[\"2020-01\"][0]\n",
    "\n",
    "        self.tweet_columns = [\n",
    "            \"created_at\",\n",
    "            \"id\",\n",
    "            \"full_text\",\n",
    "            \"cleaned_text\",\n",
    "            \"entities\",\n",
    "            \"retweet_count\",\n",
    "            \"favorite_count\",\n",
    "            \"CountyId\",\n",
    "            \"user_name\",\n",
    "            \"user_followers_count\",\n",
    "            \"user_friends_count\",\n",
    "            \"user_listed_count\",\n",
    "            \"favourites_count\",\n",
    "            \"user_location\",\n",
    "            \"geo\",\n",
    "        ]\n",
    "\n",
    "        self.output_file_path = os.path.join(self.output_folder_path, \"concated_df.csv\")\n",
    "\n",
    "    def _read_dirs(self, input_path):\n",
    "        tweets_file_set = {}\n",
    "        for month_folder in os.listdir(input_path):\n",
    "            if month_folder.startswith(\"2020\") and not month_folder.endswith(\".zip\"):\n",
    "                tweets_file_set[month_folder] = []\n",
    "                month_folder_path = os.path.join(input_path, month_folder)\n",
    "                # print(month_folder_path)\n",
    "                for tweets_file in os.listdir(month_folder_path):\n",
    "                    if tweets_file.endswith(\"json\") and tweets_file.find(\")\") == -1:\n",
    "                        # some file is duplicated\n",
    "                        tweets_file_path = os.path.join(month_folder_path, tweets_file)\n",
    "                        tweets_file_set[month_folder].append(tweets_file_path)\n",
    "\n",
    "        print(\"filepath:\", tweets_file_set.keys())\n",
    "        # print(\"all file count\", sum([len(tweets_file_set[x]) for x in tweets_file_set]))\n",
    "        return tweets_file_set\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        # Check characters to see if they are in punctuation\n",
    "        nopunc = [char for char in text if char not in string.punctuation]\n",
    "        # Join the characters again to form the string\n",
    "        nopunc = \"\".join(nopunc)\n",
    "        # convert text to lower-case\n",
    "        nopunc = nopunc.lower()\n",
    "        # remove URLs\n",
    "        nopunc = re.sub(\n",
    "            \"((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))\", \"\", nopunc\n",
    "        )\n",
    "        nopunc = re.sub(r\"http\\S+\", \"\", nopunc)\n",
    "        # remove usernames\n",
    "        nopunc = re.sub(\"@[^\\s]+\", \"\", nopunc)\n",
    "        # remove the # in #hashtag\n",
    "        nopunc = re.sub(r\"#([^\\s]+)\", r\"\\1\", nopunc)\n",
    "        # remove numbers\n",
    "        nopunc = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", nopunc)\n",
    "        nopunc = re.sub(\"\\d\", \"\", nopunc)\n",
    "        # remove repeated characters\n",
    "        nopunc = re.sub(\"(rt|corona|covid|virus)\", \"\", nopunc)\n",
    "        nopunc = word_tokenize(nopunc)\n",
    "        # remove stopwords from final word list\n",
    "        nopunc = [word for word in nopunc if word not in stopwords.words(\"english\")]\n",
    "        text = \" \".join([str(elem) for elem in nopunc]) + \"\\n\"\n",
    "        return text\n",
    "\n",
    "    def write_to_csv(self, tweet_list, output_path):\n",
    "        df = pd.DataFrame(tweet_list, columns=self.tweet_columns)\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "    def tweets_filter(self, json_obj_array):\n",
    "        \"\"\"\n",
    "        input json\n",
    "        return row list\n",
    "        \"\"\"\n",
    "        row_list = []\n",
    "        nums = len(json_obj_array)\n",
    "        with tqdm(total=nums) as pbar:\n",
    "            for json_obj in json_obj_array:\n",
    "                created_at = pd.to_datetime(json_obj.get(\"created_at\"))\n",
    "                # concverted to pd datatime\n",
    "                status_id = json_obj.get(\"id\")\n",
    "                full_text = json_obj.get(\"full_text\")\n",
    "                cleaned_text = self._clean_text(full_text)\n",
    "                # clean text\n",
    "                entities = json_obj.get(\"entities\")\n",
    "                retweet_count = json_obj.get(\"retweet_count\")\n",
    "                favorite_count = json_obj.get(\"favorite_count\")\n",
    "                CountyId = json_obj.get(\"CountyId\")\n",
    "                if CountyId is None:\n",
    "                    continue\n",
    "                user = json_obj.get(\"user\")\n",
    "                user_name = user.get(\"name\")\n",
    "                user_followers_count = user.get(\"followers_count\")\n",
    "                user_friends_count = user.get(\"friends_count\")\n",
    "                user_listed_count = user.get(\"listed_count\")\n",
    "                user_favourites_count = user.get(\"favourites_count\")\n",
    "                user_location = user.get(\"location\")\n",
    "                geo = json_obj.get(\"geo\")\n",
    "\n",
    "                row = [\n",
    "                    created_at,\n",
    "                    status_id,\n",
    "                    full_text,\n",
    "                    cleaned_text,\n",
    "                    entities,\n",
    "                    retweet_count,\n",
    "                    favorite_count,\n",
    "                    CountyId,\n",
    "                    user_name,\n",
    "                    user_followers_count,\n",
    "                    user_friends_count,\n",
    "                    user_listed_count,\n",
    "                    user_favourites_count,\n",
    "                    user_location,\n",
    "                    geo,\n",
    "                ]\n",
    "                row_list.append(row)\n",
    "                pbar.update(1)\n",
    "\n",
    "        return row_list\n",
    "\n",
    "    def read_one_json(self, json_path):\n",
    "        \"\"\"\n",
    "        return row list\n",
    "        \"\"\"\n",
    "        with open(json_path, \"r\") as j:\n",
    "            json_obj_array = ujson.load(j)\n",
    "            row_list = self.tweets_filter(json_obj_array)\n",
    "            if row_list is not None:\n",
    "                return row_list\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    def read_all_json(self, json_path_list):\n",
    "        nums = len(json_path_list)\n",
    "        print(\"reading count\", nums)\n",
    "        tweet_list = []\n",
    "        with tqdm(total=nums) as pbar:\n",
    "            for json_path in json_path_list:\n",
    "                row_list = self.read_one_json(json_path)\n",
    "                tweet_list.extend(row_list)\n",
    "                break  # for test\n",
    "                pbar.update(1)\n",
    "            print(\"all done\")\n",
    "        return tweet_list\n",
    "\n",
    "    def start_all(self, json_path_list):\n",
    "        tweet_list = self.read_all_json(json_path_list)\n",
    "        self.write_to_csv(tweet_list, self.output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath: dict_keys(['2020-01', '2020-04', '2020-03', '2020-02'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PT = PreprocessTwitter()\n",
    "len(PT.tweets_filepath_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = PT.output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_path_list = []\n",
    "for month in PT.tweets_filepath_set:\n",
    "    month_file_list = PT.tweets_filepath_set[month]\n",
    "    json_path_list.extend(month_file_list)\n",
    "len(json_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PT.start_all(json_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>entities</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>CountyId</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-30 17:04:30+00:00</td>\n",
       "      <td>1222928586493087744</td>\n",
       "      <td>RT @WHO: @DrTedros @WHOWPRO @WHOSEARO @WHO_Eur...</td>\n",
       "      <td>dedros whowpro whosearo whoeurope pahowho whoe...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>39081</td>\n",
       "      <td>Sheila Mc.</td>\n",
       "      <td>1639</td>\n",
       "      <td>1547</td>\n",
       "      <td>205</td>\n",
       "      <td>223889</td>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-30 17:04:30+00:00</td>\n",
       "      <td>1222928586891460615</td>\n",
       "      <td>RT @thehill: Italian cruise ship quarantined w...</td>\n",
       "      <td>thehill italian cruise ship quarantined thousa...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>29137</td>\n",
       "      <td>kibarracuda</td>\n",
       "      <td>221</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>59833</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-30 17:04:30+00:00</td>\n",
       "      <td>1222928587159826433</td>\n",
       "      <td>RT @awwHALEnaww: @jimsciutto @KevinMKruse Also...</td>\n",
       "      <td>awwhalenaww jimsciutto kevinmkruse also woh re...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>24031</td>\n",
       "      <td>Jane Macht</td>\n",
       "      <td>370</td>\n",
       "      <td>1883</td>\n",
       "      <td>5</td>\n",
       "      <td>31335</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-30 17:04:30+00:00</td>\n",
       "      <td>1222928587814309888</td>\n",
       "      <td>RT @Unathi_Kwaza: SAFM listener says she wasn'...</td>\n",
       "      <td>unathikwaza safm listener says wasnt worried o...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>53053</td>\n",
       "      <td>Fanie Verwey</td>\n",
       "      <td>53</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>1043</td>\n",
       "      <td>Home</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-30 17:04:30+00:00</td>\n",
       "      <td>1222928587961044992</td>\n",
       "      <td>“Goin round wiv your virus finkin your Racky B...</td>\n",
       "      <td>“ goin round wiv finkin racky balboa mayt ’ fu...</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>36067</td>\n",
       "      <td>CC</td>\n",
       "      <td>1070</td>\n",
       "      <td>859</td>\n",
       "      <td>15</td>\n",
       "      <td>21339</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at                   id  \\\n",
       "0  2020-01-30 17:04:30+00:00  1222928586493087744   \n",
       "1  2020-01-30 17:04:30+00:00  1222928586891460615   \n",
       "2  2020-01-30 17:04:30+00:00  1222928587159826433   \n",
       "3  2020-01-30 17:04:30+00:00  1222928587814309888   \n",
       "4  2020-01-30 17:04:30+00:00  1222928587961044992   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  RT @WHO: @DrTedros @WHOWPRO @WHOSEARO @WHO_Eur...   \n",
       "1  RT @thehill: Italian cruise ship quarantined w...   \n",
       "2  RT @awwHALEnaww: @jimsciutto @KevinMKruse Also...   \n",
       "3  RT @Unathi_Kwaza: SAFM listener says she wasn'...   \n",
       "4  “Goin round wiv your virus finkin your Racky B...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  dedros whowpro whosearo whoeurope pahowho whoe...   \n",
       "1  thehill italian cruise ship quarantined thousa...   \n",
       "2  awwhalenaww jimsciutto kevinmkruse also woh re...   \n",
       "3  unathikwaza safm listener says wasnt worried o...   \n",
       "4  “ goin round wiv finkin racky balboa mayt ’ fu...   \n",
       "\n",
       "                                            entities  retweet_count  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...             55   \n",
       "1  {'hashtags': [], 'symbols': [], 'user_mentions...             33   \n",
       "2  {'hashtags': [], 'symbols': [], 'user_mentions...             32   \n",
       "3  {'hashtags': [], 'symbols': [], 'user_mentions...            143   \n",
       "4  {'hashtags': [], 'symbols': [], 'user_mentions...              0   \n",
       "\n",
       "   favorite_count  CountyId     user_name  user_followers_count  \\\n",
       "0               0     39081    Sheila Mc.                  1639   \n",
       "1               0     29137   kibarracuda                   221   \n",
       "2               0     24031    Jane Macht                   370   \n",
       "3               0     53053  Fanie Verwey                    53   \n",
       "4               7     36067            CC                  1070   \n",
       "\n",
       "   user_friends_count  user_listed_count  favourites_count     user_location  \\\n",
       "0                1547                205            223889  Toronto, Ontario   \n",
       "1                 493                  1             59833      Florida, USA   \n",
       "2                1883                  5             31335      Bethesda, MD   \n",
       "3                 106                  3              1043              Home   \n",
       "4                 859                 15             21339         Liverpool   \n",
       "\n",
       "   geo  \n",
       "0  NaN  \n",
       "1  NaN  \n",
       "2  NaN  \n",
       "3  NaN  \n",
       "4  NaN  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
