{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%load_ext lab_black\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeMap:\n",
    "    def __init__(self):\n",
    "        self.scratch_path = \"/scratch/user/diya.li/\"\n",
    "        self.input_folder = \"twitter-action/depression/2D-windows-stress-topic\"\n",
    "        self.input_folder_path = os.path.join(self.scratch_path, self.input_folder)\n",
    "\n",
    "        # zip file smaple\n",
    "        self.zip_county_shp = \"twitter-action/depression/county-map/county.zip\"\n",
    "        self.zip_county_shp_path = (\n",
    "            \"zip://\" + os.path.join(self.scratch_path, self.zip_county_shp) + \"!data\"\n",
    "        )\n",
    "\n",
    "        # shape file sample\n",
    "        self.county_shp = \"twitter-action/depression/county-map/county-map.shp\"\n",
    "        self.county_shp_path = os.path.join(self.scratch_path, self.county_shp)\n",
    "\n",
    "        self.sample_input_path = \"/scratch/user/diya.li/twitter-action/depression/2D-windows-stress-topic/2020-02-22.csv\"\n",
    "\n",
    "        self.map_output_path = os.path.join(\n",
    "            self.scratch_path, \"twitter-action/depression/county-map\"\n",
    "        )\n",
    "\n",
    "        self.csv_path_list = self._get_df_path_list()\n",
    "\n",
    "        self.stress_df_columns = [\n",
    "            \"cnty_fips\",\n",
    "            \"state_name\",\n",
    "            \"state_fips\",\n",
    "            \"cnty_name\",\n",
    "            \"state_abbr\",\n",
    "            \"geometry\",\n",
    "            \"avg_stress\",\n",
    "            \"date\",\n",
    "        ]\n",
    "\n",
    "    def _get_df_path_list(self):\n",
    "        l = []\n",
    "        for df_path in os.listdir(self.input_folder_path):\n",
    "            if df_path.endswith(\"csv\"):\n",
    "                l.append(df_path)\n",
    "        l.sort()\n",
    "        return l\n",
    "\n",
    "    def preprocess_county_shp(self, shp_obj):\n",
    "        \"\"\"deprecated function\"\"\"\n",
    "        shp_obj = shp_obj.drop(\n",
    "            [\n",
    "                \"OBJECTID\",\n",
    "                \"Value\",\n",
    "                \"Shape_Leng\",\n",
    "                \"SmoValue\",\n",
    "                \"DrValue\",\n",
    "                \"InacValue\",\n",
    "                \"MedCValue\",\n",
    "                \"Income\",\n",
    "                \"Shape_Le_1\",\n",
    "                \"Shape_Area\",\n",
    "                \"Deathrate\",\n",
    "                \"Diabetes\",\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        shp_obj = shp_obj[shp_obj[\"state_name\"] != \"Virgin Islands of the U.S.\"]\n",
    "        return shp_obj\n",
    "\n",
    "    def write_shp(self, shp_obj, output_path, driver=\"ESRI Shapefile\"):\n",
    "        shp_obj.to_file(output_path, driver=driver)\n",
    "\n",
    "    def test_plot(self, shp_obj):\n",
    "        world = geopandas.read_file(geopandas.datasets.get_path(\"naturalearth_lowres\"))\n",
    "        world = world[world[\"continent\"] == \"North America\"]\n",
    "        # base = world.plot(color=\"white\", edgecolor=\"black\")\n",
    "        shp_obj.plot()\n",
    "\n",
    "    def read_county_shp(self, shp_path):\n",
    "        county_shp_obj = geopandas.read_file(shp_path)\n",
    "        county_shp_obj[\"cnty_fips\"] = county_shp_obj[\"cnty_fips\"].apply(\n",
    "            lambda x: np.float64(x)\n",
    "        )\n",
    "        return county_shp_obj\n",
    "\n",
    "    def read_one_csv(self, df_path):\n",
    "        df = pd.read_csv(df_path, lineterminator=\"\\n\")\n",
    "        return df\n",
    "\n",
    "    def get_stress_item():\n",
    "        pass\n",
    "\n",
    "    def read_csv_folder_with_stress(self, shp_obj):\n",
    "        \"\"\"is function is used to group the stress string by date\"\"\"\n",
    "        nums = len(self.csv_path_list)\n",
    "        concated_df = pd.DataFrame()\n",
    "        with tqdm(total=nums) as pbar:\n",
    "            for df_path in self.csv_path_list:\n",
    "                df_path = os.path.join(self.input_folder_path, df_path)\n",
    "                df = self.read_one_csv(df_path)\n",
    "\n",
    "                date_string = df_path.split(\"/\")[-1].replace(\".csv\", \"\")\n",
    "                date_obj = str(pd.to_datetime(date_string)) + \"+00:00\"\n",
    "                row_list = []\n",
    "\n",
    "                for group in df.groupby(\"CountyId\"):\n",
    "                    row = shp_obj[shp_obj[\"cnty_fips\"] == group[0]].values.tolist()\n",
    "                    if len(row) == 0:\n",
    "                        continue\n",
    "                    row = row[0]\n",
    "\n",
    "                    avg_stress = sum(group[1][\"stress_rate\"].values) / group[1].shape[0]\n",
    "\n",
    "                    row.append(avg_stress)\n",
    "                    row.append(date_obj)\n",
    "\n",
    "                    row_list.append(row)\n",
    "\n",
    "                # print(row_list[0])\n",
    "                new_df = pd.DataFrame(row_list, columns=self.stress_df_columns)\n",
    "                concated_df = pd.concat([concated_df, new_df])\n",
    "\n",
    "                # write to geojson\n",
    "                gdf = geopandas.GeoDataFrame(concated_df, geometry=concated_df.geometry)\n",
    "                MM.write_shp(\n",
    "                    gdf, \"./temp_map/{}.gpkg\".format(date_string), driver=\"GPKG\"\n",
    "                )\n",
    "                pbar.update(1)\n",
    "        return concated_df\n",
    "\n",
    "    def read_csv_folder(self):\n",
    "        nums = len(self.csv_path_list)\n",
    "        concated_df = pd.DataFrame()\n",
    "        with tqdm(total=nums) as pbar:\n",
    "            for df_path in self.csv_path_list:\n",
    "                df_path = os.path.join(self.input_folder_path, df_path)\n",
    "                date_string = df_path.split(\"/\")[-1].replace(\".csv\", \"\")\n",
    "                df = self.read_one_csv(df_path)\n",
    "                df[\"date\"] = pd.to_datetime(date_string)\n",
    "                concated_df = pd.concat([concated_df, df])\n",
    "                pbar.update(1)\n",
    "        return concated_df\n",
    "\n",
    "    def add_geometory(self, df, shp_obj):\n",
    "        \"\"\"todo\"\"\"\n",
    "        nums = df.shape[0]\n",
    "        with tqdm(total=nums) as pbar:\n",
    "            for index in range(nums):\n",
    "                countyId = str(df.iloc[index][\"CountyId\"])\n",
    "\n",
    "    def all_county_stress_rate(self, df, shp_obj):\n",
    "        # shp_obj[\"cnty_fips\"] = shp_obj[\"cnty_fips\"].apply(lambda x: str(np.float64(x)))\n",
    "\n",
    "        avg_stress_set = {}\n",
    "\n",
    "        for group in df.groupby(\"CountyId\"):\n",
    "            avg_stress = sum(group[1][\"stress_rate\"].values) / group[1].shape[0]\n",
    "            county_df_num = group[0]\n",
    "            # print(county_df[0], county_df_num, avg_stress)\n",
    "            # shp_obj.loc[\n",
    "            #    shp_obj[\"cnty_fips\"] == county_df_num, [\"avg_stress\"]\n",
    "            # ] = avg_stress\n",
    "            avg_stress_set[county_df_num] = avg_stress\n",
    "        # print(avg_stress_set)\n",
    "        shp_obj[\"avg_stress\"] = shp_obj[\"cnty_fips\"].apply(\n",
    "            lambda x: avg_stress_set.get(x)\n",
    "        )\n",
    "\n",
    "        return shp_obj\n",
    "\n",
    "    def write_topic(self, concated_df):\n",
    "        topic_names = [\"topic_{}\".format(x) for x in range(9)]\n",
    "        for topic in topic_names:\n",
    "            temp_df = concated_df[concated_df[topic] != 0.0]\n",
    "            #     temp_df.to_csv(\"topic-map/{}.csv\".format(topic), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM = MakeMap()\n",
    "# tmp_df = MM.read_one_csv(MM.sample_input_path)\n",
    "# MM.write_shp(tmp_shp)\n",
    "# MM.test_plot(tmp_shp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_df = MM.read_one_csv(MM.sample_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_df[\"created_at\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concated_df = MM.read_csv_folder()\n",
    "# concated_df_unique = concated_df.drop_duplicates(subset=\"cleaned_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [15:13<00:00, 13.24s/it]\n"
     ]
    }
   ],
   "source": [
    "shp_obj = MM.read_county_shp(MM.county_shp_path)\n",
    "# tmp_shp = MM.all_county_stress_rate(concated_df_unique, tmp_shp)\n",
    "concated_df = MM.read_csv_folder_with_stress(shp_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-01-22 00:00:00+00:00'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_df[\"date\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnty_fips</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>cnty_name</th>\n",
       "      <th>state_abbr</th>\n",
       "      <th>geometry</th>\n",
       "      <th>avg_stress</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1121.0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>01</td>\n",
       "      <td>Talladega</td>\n",
       "      <td>AL</td>\n",
       "      <td>POLYGON ((-9627906.4789 3910078.557800002, -96...</td>\n",
       "      <td>0.698620</td>\n",
       "      <td>2020-01-22 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4007.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>04</td>\n",
       "      <td>Gila</td>\n",
       "      <td>AZ</td>\n",
       "      <td>POLYGON ((-12411049.494 4029747.775899999, -12...</td>\n",
       "      <td>0.510247</td>\n",
       "      <td>2020-01-22 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4013.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>04</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>AZ</td>\n",
       "      <td>POLYGON ((-12361191.7715 3958648.675099999, -1...</td>\n",
       "      <td>0.669872</td>\n",
       "      <td>2020-01-22 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4023.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>04</td>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>AZ</td>\n",
       "      <td>POLYGON ((-12295524.7839 3676678.829099998, -1...</td>\n",
       "      <td>0.941334</td>\n",
       "      <td>2020-01-22 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5043.0</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>05</td>\n",
       "      <td>Drew</td>\n",
       "      <td>AR</td>\n",
       "      <td>POLYGON ((-10239094.5889 3948497.221799999, -1...</td>\n",
       "      <td>0.751438</td>\n",
       "      <td>2020-01-22 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cnty_fips state_name state_fips   cnty_name state_abbr  \\\n",
       "0     1121.0    Alabama         01   Talladega         AL   \n",
       "1     4007.0    Arizona         04        Gila         AZ   \n",
       "2     4013.0    Arizona         04    Maricopa         AZ   \n",
       "3     4023.0    Arizona         04  Santa Cruz         AZ   \n",
       "4     5043.0   Arkansas         05        Drew         AR   \n",
       "\n",
       "                                            geometry  avg_stress  \\\n",
       "0  POLYGON ((-9627906.4789 3910078.557800002, -96...    0.698620   \n",
       "1  POLYGON ((-12411049.494 4029747.775899999, -12...    0.510247   \n",
       "2  POLYGON ((-12361191.7715 3958648.675099999, -1...    0.669872   \n",
       "3  POLYGON ((-12295524.7839 3676678.829099998, -1...    0.941334   \n",
       "4  POLYGON ((-10239094.5889 3948497.221799999, -1...    0.751438   \n",
       "\n",
       "                        date  \n",
       "0  2020-01-22 00:00:00+00:00  \n",
       "1  2020-01-22 00:00:00+00:00  \n",
       "2  2020-01-22 00:00:00+00:00  \n",
       "3  2020-01-22 00:00:00+00:00  \n",
       "4  2020-01-22 00:00:00+00:00  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MM.write_shp(tmp_shp, \"./temp_map/sum.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(concated_df, geometry=concated_df.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-01-22 00:00:00+00:00'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf[\"date\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf[\"date\"] = gdf[\"date\"].apply(lambda x: str(x))\n",
    "# gdf[\"date\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM.write_shp(gdf, \"./temp_map/sum-withdate.shp\", driver=\"ESRI Shapefile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "stress_rate_list = []\n",
    "for county_df in concated_df_unique.groupby(\"CountyId\"):\n",
    "\n",
    "    avg_stress = sum(county_df[1][\"stress_rate\"].values) / county_df[1].shape[0]\n",
    "    # print(county_df[0], county_df[1].shape, avg_stress)\n",
    "    stress_rate_list.append(avg_stress)\n",
    "    # stress_rate/num tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-25e56ff1b373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Date' is not defined"
     ]
    }
   ],
   "source": [
    "Date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
